{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKOZtjI-Z0yg"
      },
      "source": [
        "# DACON 월간 데이콘 한국어 문장 관계 분류 경진대회\n",
        "[월간 데이콘 한국어 문장 관계 분류 경진대회](https://dacon.io/competitions/official/235875/overview/description)  \n",
        "[참고 노트북 | Hugging Face를 활용한 Modeling(public: 0.841)](https://dacon.io/competitions/official/235875/codeshare/4520?page=1&dtype=recent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wakv20FrZ0yj"
      },
      "source": [
        "### EDA\n",
        "데이터셋의 구조와 문장 분포 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jflBR0pbZ0yj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import  pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# import koreanize_matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1umLnGXZ6aP",
        "outputId": "1ff925a6-a9e2-4976-af95-9521cb3193d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grXjpfP8Z0yk"
      },
      "source": [
        "#### Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ddspm-bsZ0yl",
        "outputId": "cf512e64-f6bd-48f8-f62d-720338a36dcb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((24998, 4), (1666, 4))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# PATH = \"./dataset/\"\n",
        "PATH = \"/content/drive/MyDrive/Classifying Korean Sentence Relationships/dataset\"\n",
        "\n",
        "train = pd.read_csv(os.path.join(PATH, \"train_data.csv\"), encoding=\"utf8\")\n",
        "test =  pd.read_csv(os.path.join(PATH, \"test_data.csv\"),  encoding=\"utf8\")\n",
        "\n",
        "train.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wP7gS1FoZ0ym",
        "outputId": "d4cd2c9b-a7de-441e-86f4-623ed53d51ca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0ac69199-d446-4866-8083-14fb3f445289\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서, 소년이나 장정들이...</td>\n",
              "      <td>씨름의 여자들의 놀이이다.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나,...</td>\n",
              "      <td>자작극을 벌인 이는 3명이다.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다.</td>\n",
              "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
              "      <td>원주민들은 종합대책에 만족했다.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면, 이런 상황에서는...</td>\n",
              "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ac69199-d446-4866-8083-14fb3f445289')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ac69199-d446-4866-8083-14fb3f445289 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ac69199-d446-4866-8083-14fb3f445289');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   index                                            premise  \\\n",
              "0      0  씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서, 소년이나 장정들이...   \n",
              "1      1  삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나,...   \n",
              "2      2                    이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다.   \n",
              "3      3  광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...   \n",
              "4      4  진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면, 이런 상황에서는...   \n",
              "\n",
              "                                hypothesis          label  \n",
              "0                           씨름의 여자들의 놀이이다.  contradiction  \n",
              "1                         자작극을 벌인 이는 3명이다.  contradiction  \n",
              "2  예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.     entailment  \n",
              "3                        원주민들은 종합대책에 만족했다.        neutral  \n",
              "4       이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.        neutral  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_814eBgRZ0ym"
      },
      "source": [
        "#### 분포 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1wbgiO2Z0yn",
        "outputId": "d40ff7b0-68de-4927-d2d5-9afb0207e595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 24998 entries, 0 to 24997\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   index       24998 non-null  int64 \n",
            " 1   premise     24998 non-null  object\n",
            " 2   hypothesis  24998 non-null  object\n",
            " 3   label       24998 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 781.3+ KB\n",
            "None\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1666 entries, 0 to 1665\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   index       1666 non-null   int64 \n",
            " 1   premise     1666 non-null   object\n",
            " 2   hypothesis  1666 non-null   object\n",
            " 3   label       1666 non-null   object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 52.2+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(train.info(), end=\"\\n\\n\")\n",
        "print(test.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "QAWa_FSQZ0yo",
        "outputId": "96f94e0b-e1a9-4168-a664-29c2098b8cef"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(facecolor=\"white\")\n",
        "plt.title(\"Train Labels Distribution\")\n",
        "plt.pie(train[\"label\"].value_counts().values, labels=train[\"label\"].value_counts().index, autopct=\"%.2f%%\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "52xgaXPTZ0yo",
        "outputId": "7dd8d8bc-1992-40bc-cd22-47d4b25745b1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.countplot(x=train[\"label\"]).set_title(\"Train Labels Distribution - Count Plot\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXoXAaPVZ0yp"
      },
      "source": [
        "#### 결측치 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "B0D6iDqoZ0yp",
        "outputId": "c4f97dc2-082d-47bf-a5eb-c163233f56f4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x360 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(12,  5))\n",
        "sns.heatmap(train.isna(), ax=ax[0])\n",
        "sns.heatmap(test.isna(), ax=ax[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dht5kb7RZ0yp"
      },
      "source": [
        "#### 전제, 가설 길이 확인\n",
        "`train`에 존재하는 전제(Premise)와 가설(Hypothesus)의 길이를 확인하고 이를 통해 `Tokenizer`의  `max_length`  설정이 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoezUssdZ0yp",
        "outputId": "b9409b7a-582b-4444-d0e4-73822a8e2a62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Premise -\n",
            "Max Len: 90\n",
            "Mean Len: 45.406552524201935\n",
            "Min Len: 19\n",
            "\n",
            "Hypothesis -\n",
            "Max Len: 103\n",
            "Mean Len: 24.924433954716378\n",
            "Min Len: 5\n"
          ]
        }
      ],
      "source": [
        "max_len = np.max(train[\"premise\"].str.len())\n",
        "min_len = np.min(train[\"premise\"].str.len())\n",
        "mean_len = np.mean(train[\"premise\"].str.len())\n",
        "print(f\"Premise -\\nMax Len: {max_len}\\nMean Len: {mean_len}\\nMin Len: {min_len}\")\n",
        "\n",
        "max_len = np.max(train[\"hypothesis\"].str.len())\n",
        "min_len = np.min(train[\"hypothesis\"].str.len())\n",
        "mean_len = np.mean(train[\"hypothesis\"].str.len())\n",
        "print()\n",
        "print(f\"Hypothesis -\\nMax Len: {max_len}\\nMean Len: {mean_len}\\nMin Len: {min_len}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "EIuYUeQfZ0yq",
        "outputId": "3f660c88-f1ab-4a85-844e-8687b8efa733"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.title(\"Premise Length\")\n",
        "plt.hist(train[\"premise\"].str.len());"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onqEEnHFZ0yq"
      },
      "source": [
        "#### Test Preporcessing\n",
        "전제, 가설에 존재하는 한글 단어가 아닌 다른 단어들은 전부 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "o-vD72-mZ0yq"
      },
      "outputs": [],
      "source": [
        "train[\"premise\"] = train[\"premise\"].str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣 0-9]\",\"\", regex=True)\n",
        "test[\"premise\"] = test[\"premise\"].str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣 0-9]\",\"\", regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "en9qGIrOZ0yr"
      },
      "outputs": [],
      "source": [
        "train[\"hypothesis\"] = train[\"hypothesis\"].str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣 0-9]\",\"\", regex=True)\n",
        "test[\"hypothesis\"] = test[\"hypothesis\"].str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣 0-9]\",\"\", regex=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER5HEgwuZ0yr"
      },
      "source": [
        "### Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uqdtt07RaX8h",
        "outputId": "e3889b4a-dcd3-49ce-c9ce-afae00ad2a8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "68u8UBlMZ0yr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import AutoModelForSequenceClassification, AutoConfig, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0_HprLIZ0yr",
        "outputId": "66923c7e-8a1f-4e95-af91-26f685b330b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90tGVTO_Z0ys"
      },
      "source": [
        "#### Load Tokenizer\n",
        "Hugging Face Hub에 존재하는 사전 훈련된 tokenizer와 모델 및 모델 설정 이용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAp5PGHwZ0ys",
        "outputId": "f7f32799-06bf-4db0-c12c-008d93903f7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAME = \"klue/roberta-large\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "config =  AutoConfig.from_pretrained(MODEL_NAME)\n",
        "config.num_labels = 3\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FPWk6EwZ0ys",
        "outputId": "eb7a53ae-cdc1-4250-f3ce-429964d5fb59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RobertaForSequenceClassification(\n",
            "  (roberta): RobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(32000, 1024, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 1024)\n",
            "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (12): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (13): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (14): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (15): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (16): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (17): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (18): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (19): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (20): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (21): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (22): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (23): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (classifier): RobertaClassificationHead(\n",
            "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cE2KmoVhZ0ys",
        "outputId": "83140f20-1dcf-4e5b-8532-75558012596e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RobertaConfig {\n",
            "  \"_name_or_path\": \"klue/roberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"tokenizer_class\": \"BertTokenizer\",\n",
            "  \"transformers_version\": \"4.21.3\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MROrc83CZ0yt"
      },
      "source": [
        "#### Tokenizing\n",
        "Train 데이터를 Train과 Validation으로 나누고 각각 데이터를 토큰화  \n",
        "토큰화되는 문장ㅇ은 전제와 가설을 `concat`한 문장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUxz9HKmZ0yt",
        "outputId": "bc2a4f7c-21d8-4d9c-d14a-3551cc681f93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((19998, 4), (5000, 4))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train, valid = train_test_split(train, test_size=0.2, shuffle=True, stratify=train[\"label\"])\n",
        "\n",
        "train.shape, valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "3cRSWD4DZ0yt"
      },
      "outputs": [],
      "source": [
        "tokenized_train = tokenizer(\n",
        "    list(train[\"premise\"]),\n",
        "    list(train[\"hypothesis\"]),\n",
        "    return_tensors=\"pt\",\n",
        "    max_length=256,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    add_special_tokens=True\n",
        ")\n",
        "\n",
        "tokenized_valid = tokenizer(\n",
        "    list(valid[\"premise\"]),\n",
        "    list(valid[\"hypothesis\"]),\n",
        "    return_tensors=\"pt\",\n",
        "    max_length=256,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    add_special_tokens=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kptJL5nnZ0yt",
        "outputId": "5a5362a8-7387-4dbb-a017-128374a70a1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([    0,  3624,  2170,  4107,  2211,  6233,  7475,  2470,  1485, 11497,\n",
            "         2052,  3669,  7399,  2079,  5289,  2138, 14689,  4683,  7629, 31302,\n",
            "         2259,  4258,  2062,     2, 11497,  2073,  4041,  2211,  2299,  3683,\n",
            "         7475,  2116,  3662,  2205,  2062,     2,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1])\n"
          ]
        }
      ],
      "source": [
        "print(tokenized_train[\"input_ids\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh_lR84ZZ0yt",
        "outputId": "bf971859-20eb-4644-95ea-92c4ccbe36ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS] 때문에 22명으로 기재한 위 칼럼이 사실 왜곡의 의도를 지녔다고 판정하기는 어렵다 [SEP] 칼럼은 21명까지만 기재가 가능하다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(tokenized_train[\"input_ids\"][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WdDozDMYZ0yt"
      },
      "outputs": [],
      "source": [
        "class BERTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, pair_dataset, label):\n",
        "        self.pair_dataset = pair_dataset\n",
        "        self.label = label\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key:val[idx].clone().detach() for key, val in self.pair_dataset.items()}\n",
        "        item[\"label\"] = torch.tensor(self.label[idx])\n",
        "        return item\n",
        "    def __len__(self):\n",
        "        return len(self.label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "NsnRspPMZ0yu"
      },
      "outputs": [],
      "source": [
        "def label_to_num(label):\n",
        "    label_dict = {\"entailment\":0, \"contradiction\":1, \"neutral\":2, \"answer\":3}\n",
        "    num_label = []\n",
        "    for v in label:\n",
        "        num_label.append(label_dict[v])\n",
        "    return num_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "QSm28MGhZ0yu"
      },
      "outputs": [],
      "source": [
        "train_label = label_to_num(train[\"label\"].values)\n",
        "valid_label = label_to_num(valid[\"label\"].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAqHHAWIZ0yu",
        "outputId": "fc4dad8a-49d2-412e-98b0-4db91a303c08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19998\n",
            "{'input_ids': tensor([    0,  4739,  6233, 15447,   570,  2408,  2069,  9381, 19521,  1545,\n",
            "         2256,   570,  2408,  2069,  8585,  2073,  6099,  2470, 19777,  2348,\n",
            "         2209,  8739,     2, 15447,   570,  2408,  2069,  9381, 19521,  1545,\n",
            "         2256,   570,  2408,  2069, 16925,  2470,  6099,  2470, 19777,  2348,\n",
            "         2209,  8739,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0]), 'label': tensor(0)}\n",
            "[CLS] 진정으로 퍼스트 건담을 계승하고 제타 건담을 뛰어넘은 영원한 걸작애니메이션 [SEP] 퍼스트 건담을 계승하고 제타 건담을 추월한 영원한 걸작애니메이션 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ]
        }
      ],
      "source": [
        "train_dataset = BERTDataset(tokenized_train, train_label)\n",
        "valid_dataset = BERTDataset(tokenized_valid, valid_label)\n",
        "\n",
        "print(train_dataset.__len__())\n",
        "print(train_dataset.__getitem__(19997))\n",
        "print(tokenizer.decode(train_dataset.__getitem__(19997)[\"input_ids\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_xkLStscZ0yu"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "    # validation을 위한 metrics func.\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    probs = pred.predictions\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\":acc}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ea2UOQRQZ0yu"
      },
      "outputs": [],
      "source": [
        "training_ars = TrainingArguments(\n",
        "    output_dir=\"./result\",\n",
        "    num_train_epochs=7,\n",
        "    per_device_train_batch_size=32,\n",
        "    save_total_limit=5,\n",
        "    save_steps=500,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_ars,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-mbRshzIZ0yu",
        "outputId": "7f711f16-7aa0-4637-9c07-ade7f02564df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 19998\n",
            "  Num Epochs = 7\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 4375\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4375' max='4375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4375/4375 2:23:00, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.116300</td>\n",
              "      <td>1.099470</td>\n",
              "      <td>0.339600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.109100</td>\n",
              "      <td>1.099542</td>\n",
              "      <td>0.339600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.106200</td>\n",
              "      <td>1.104970</td>\n",
              "      <td>0.339600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.104500</td>\n",
              "      <td>1.109457</td>\n",
              "      <td>0.342400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.103100</td>\n",
              "      <td>1.098380</td>\n",
              "      <td>0.339600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.102200</td>\n",
              "      <td>1.098596</td>\n",
              "      <td>0.339600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.101200</td>\n",
              "      <td>1.098708</td>\n",
              "      <td>0.342400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.101300</td>\n",
              "      <td>1.098195</td>\n",
              "      <td>0.342400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./result/checkpoint-500\n",
            "Configuration saved in ./result/checkpoint-500/config.json\n",
            "Model weights saved in ./result/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in ./result/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in ./result/checkpoint-500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./result/checkpoint-1000\n",
            "Configuration saved in ./result/checkpoint-1000/config.json\n",
            "Model weights saved in ./result/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in ./result/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in ./result/checkpoint-1000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./result/checkpoint-1500\n",
            "Configuration saved in ./result/checkpoint-1500/config.json\n",
            "Model weights saved in ./result/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in ./result/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in ./result/checkpoint-1500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./result/checkpoint-2000\n",
            "Configuration saved in ./result/checkpoint-2000/config.json\n",
            "Model weights saved in ./result/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in ./result/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in ./result/checkpoint-2000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./result/checkpoint-2500\n",
            "Configuration saved in ./result/checkpoint-2500/config.json\n",
            "Model weights saved in ./result/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in ./result/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in ./result/checkpoint-2500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./result/checkpoint-3000\n",
            "Configuration saved in ./result/checkpoint-3000/config.json\n",
            "Model weights saved in ./result/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in ./result/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in ./result/checkpoint-3000/special_tokens_map.json\n",
            "Deleting older checkpoint [result/checkpoint-500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./result/checkpoint-3500\n",
            "Configuration saved in ./result/checkpoint-3500/config.json\n",
            "Model weights saved in ./result/checkpoint-3500/pytorch_model.bin\n",
            "tokenizer config file saved in ./result/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in ./result/checkpoint-3500/special_tokens_map.json\n",
            "Deleting older checkpoint [result/checkpoint-1000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./result/checkpoint-4000\n",
            "Configuration saved in ./result/checkpoint-4000/config.json\n",
            "Model weights saved in ./result/checkpoint-4000/pytorch_model.bin\n",
            "tokenizer config file saved in ./result/checkpoint-4000/tokenizer_config.json\n",
            "Special tokens file saved in ./result/checkpoint-4000/special_tokens_map.json\n",
            "Deleting older checkpoint [result/checkpoint-1500] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./result/checkpoint-4000 (score: 1.098195195198059).\n",
            "Configuration saved in ./result/best_model/config.json\n",
            "Model weights saved in ./result/best_model/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "trainer.train()\n",
        "model.save_pretrained(\"./result/best_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11ap39YjZguE",
        "outputId": "b62ff273-18f9-4f20-9cc2-75cb15a63665"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file https://huggingface.co/klue/roberta-large/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/4eb906e7d0da2b04e56c7cc31ba068d7c295240a51690153c2ced71c9e4c9fc5.d1b86bed49516351c7bb29b19d7e7be2ab53b931bcb1f9b2aacfb71f2124d25a\n",
            "loading file https://huggingface.co/klue/roberta-large/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/360b579947002f14f22331a026821b56f70679f1be1e95fe5dc5a80edc4a59e0.44c30ade4958fcfd446e66025e10a5b380cdd0bbe9b3fb7a794f357e7f0f34c2\n",
            "loading file https://huggingface.co/klue/roberta-large/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/klue/roberta-large/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/1a24ab4628028ed80dea35ce3334a636dc656fd9a17a09bad377f88f0cbecdac.70c17d6e4d492c8f24f5bb97ab56c7f272e947112c6faf9dd846da42ba13eb23\n",
            "loading file https://huggingface.co/klue/roberta-large/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/8f31ccbd66730704a8400c96db0647b10c47cd0c838ea2cabf0a86ef878f31cf.5b0ba083b234382bb4c99ee0c9f4fca4cadaa053dd17c32dabfe0de2f629af1f\n",
            "loading configuration file ./result/checkpoint-4000/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./result/checkpoint-4000\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"tokenizer_class\": \"BertTokenizer\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.3\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "loading weights file ./result/checkpoint-4000/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
            "\n",
            "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at ./result/checkpoint-4000.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PreTrainedTokenizerFast(name_or_path='klue/roberta-large', vocab_size=32000, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "Tokenizer_NAME = \"klue/roberta-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(Tokenizer_NAME)\n",
        "\n",
        "MODEL_NAME = './result/checkpoint-4000'\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "model.resize_token_embeddings(tokenizer.vocab_size)\n",
        "model.to(device)\n",
        "\n",
        "print(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YxxPgNzi8m8",
        "outputId": "a50deb4c-ca71-41fa-b457-aa0c95dbc015"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1666\n",
            "{'input_ids': tensor([    0,   720,  3994,  2052, 10428,  2775,   647,  3657,  2119,  1085,\n",
            "            3,     2,   720,  3994,  2052,   911,  2075,  3669,  2119,  3926,\n",
            "         2088,  1513,  2359, 13964,     2,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'label': tensor(3)}\n",
            "[CLS] 18일 귀국이라 발인도 지켜드리지 못해 더욱 죄송할 따름입니다 [SEP] 18일 배를 타고 여행을 떠났습니다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ]
        }
      ],
      "source": [
        "test_label = label_to_num(test['label'].values)\n",
        "\n",
        "tokenized_test = tokenizer(\n",
        "    list(test['premise']),\n",
        "    list(test['hypothesis']),\n",
        "    return_tensors=\"pt\",\n",
        "    max_length=128,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    add_special_tokens=True\n",
        ")\n",
        "\n",
        "test_dataset = BERTDataset(tokenized_test, test_label)\n",
        "\n",
        "print(test_dataset.__len__())\n",
        "print(test_dataset.__getitem__(1665))\n",
        "print(tokenizer.decode(test_dataset.__getitem__(6)['input_ids']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCwEJgxsi-4s",
        "outputId": "e50ee63f-ce50-419c-f1ab-e922092df1c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 105/105 [00:21<00:00,  4.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "output_pred = []\n",
        "output_prob = []\n",
        "\n",
        "for i, data in enumerate(tqdm(dataloader)):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            input_ids=data['input_ids'].to(device),\n",
        "            attention_mask=data['attention_mask'].to(device),\n",
        "            token_type_ids=data['token_type_ids'].to(device)\n",
        "        )\n",
        "    logits = outputs[0]\n",
        "    prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    result = np.argmax(logits, axis=-1)\n",
        "\n",
        "    output_pred.append(result)\n",
        "    output_prob.append(prob)\n",
        "  \n",
        "pred_answer, output_prob = np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()\n",
        "print(pred_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1jAovQBjAvj",
        "outputId": "df908edf-aab7-4f0b-8f35-976d74ba153f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0, 'entailment'], [1, 'entailment'], [2, 'entailment'], [3, 'entailment'], [4, 'entailment'], [5, 'entailment'], [6, 'entailment'], [7, 'entailment'], [8, 'entailment'], [9, 'entailment'], [10, 'entailment'], [11, 'entailment'], [12, 'entailment'], [13, 'entailment'], [14, 'entailment'], [15, 'entailment'], [16, 'entailment'], [17, 'entailment'], [18, 'entailment'], [19, 'entailment'], [20, 'entailment'], [21, 'entailment'], [22, 'entailment'], [23, 'entailment'], [24, 'entailment'], [25, 'entailment'], [26, 'entailment'], [27, 'entailment'], [28, 'entailment'], [29, 'entailment'], [30, 'entailment'], [31, 'entailment'], [32, 'entailment'], [33, 'entailment'], [34, 'entailment'], [35, 'entailment'], [36, 'entailment'], [37, 'entailment'], [38, 'entailment'], [39, 'entailment'], [40, 'entailment'], [41, 'entailment'], [42, 'entailment'], [43, 'entailment'], [44, 'entailment'], [45, 'entailment'], [46, 'entailment'], [47, 'entailment'], [48, 'entailment'], [49, 'entailment'], [50, 'entailment'], [51, 'entailment'], [52, 'entailment'], [53, 'entailment'], [54, 'entailment'], [55, 'entailment'], [56, 'entailment'], [57, 'entailment'], [58, 'entailment'], [59, 'entailment'], [60, 'entailment'], [61, 'entailment'], [62, 'entailment'], [63, 'entailment'], [64, 'entailment'], [65, 'entailment'], [66, 'entailment'], [67, 'entailment'], [68, 'entailment'], [69, 'entailment'], [70, 'entailment'], [71, 'entailment'], [72, 'entailment'], [73, 'entailment'], [74, 'entailment'], [75, 'entailment'], [76, 'entailment'], [77, 'entailment'], [78, 'entailment'], [79, 'entailment'], [80, 'entailment'], [81, 'entailment'], [82, 'entailment'], [83, 'entailment'], [84, 'entailment'], [85, 'entailment'], [86, 'entailment'], [87, 'entailment'], [88, 'entailment'], [89, 'entailment'], [90, 'entailment'], [91, 'entailment'], [92, 'entailment'], [93, 'entailment'], [94, 'entailment'], [95, 'entailment'], [96, 'entailment'], [97, 'entailment'], [98, 'entailment'], [99, 'entailment'], [100, 'entailment'], [101, 'entailment'], [102, 'entailment'], [103, 'entailment'], [104, 'entailment'], [105, 'entailment'], [106, 'entailment'], [107, 'entailment'], [108, 'entailment'], [109, 'entailment'], [110, 'entailment'], [111, 'entailment'], [112, 'entailment'], [113, 'entailment'], [114, 'entailment'], [115, 'entailment'], [116, 'entailment'], [117, 'entailment'], [118, 'entailment'], [119, 'entailment'], [120, 'entailment'], [121, 'entailment'], [122, 'entailment'], [123, 'entailment'], [124, 'entailment'], [125, 'entailment'], [126, 'entailment'], [127, 'entailment'], [128, 'entailment'], [129, 'entailment'], [130, 'entailment'], [131, 'entailment'], [132, 'entailment'], [133, 'entailment'], [134, 'entailment'], [135, 'entailment'], [136, 'entailment'], [137, 'entailment'], [138, 'entailment'], [139, 'entailment'], [140, 'entailment'], [141, 'entailment'], [142, 'entailment'], [143, 'entailment'], [144, 'entailment'], [145, 'entailment'], [146, 'entailment'], [147, 'entailment'], [148, 'entailment'], [149, 'entailment'], [150, 'entailment'], [151, 'entailment'], [152, 'entailment'], [153, 'entailment'], [154, 'entailment'], [155, 'entailment'], [156, 'entailment'], [157, 'entailment'], [158, 'entailment'], [159, 'entailment'], [160, 'entailment'], [161, 'entailment'], [162, 'entailment'], [163, 'entailment'], [164, 'entailment'], [165, 'entailment'], [166, 'entailment'], [167, 'entailment'], [168, 'entailment'], [169, 'entailment'], [170, 'entailment'], [171, 'entailment'], [172, 'entailment'], [173, 'entailment'], [174, 'entailment'], [175, 'entailment'], [176, 'entailment'], [177, 'entailment'], [178, 'entailment'], [179, 'entailment'], [180, 'entailment'], [181, 'entailment'], [182, 'entailment'], [183, 'entailment'], [184, 'entailment'], [185, 'entailment'], [186, 'entailment'], [187, 'entailment'], [188, 'entailment'], [189, 'entailment'], [190, 'entailment'], [191, 'entailment'], [192, 'entailment'], [193, 'entailment'], [194, 'entailment'], [195, 'entailment'], [196, 'entailment'], [197, 'entailment'], [198, 'entailment'], [199, 'entailment'], [200, 'entailment'], [201, 'entailment'], [202, 'entailment'], [203, 'entailment'], [204, 'entailment'], [205, 'entailment'], [206, 'entailment'], [207, 'entailment'], [208, 'entailment'], [209, 'entailment'], [210, 'entailment'], [211, 'entailment'], [212, 'entailment'], [213, 'entailment'], [214, 'entailment'], [215, 'entailment'], [216, 'entailment'], [217, 'entailment'], [218, 'entailment'], [219, 'entailment'], [220, 'entailment'], [221, 'entailment'], [222, 'entailment'], [223, 'entailment'], [224, 'entailment'], [225, 'entailment'], [226, 'entailment'], [227, 'entailment'], [228, 'entailment'], [229, 'entailment'], [230, 'entailment'], [231, 'entailment'], [232, 'entailment'], [233, 'entailment'], [234, 'entailment'], [235, 'entailment'], [236, 'entailment'], [237, 'entailment'], [238, 'entailment'], [239, 'entailment'], [240, 'entailment'], [241, 'entailment'], [242, 'entailment'], [243, 'entailment'], [244, 'entailment'], [245, 'entailment'], [246, 'entailment'], [247, 'entailment'], [248, 'entailment'], [249, 'entailment'], [250, 'entailment'], [251, 'entailment'], [252, 'entailment'], [253, 'entailment'], [254, 'entailment'], [255, 'entailment'], [256, 'entailment'], [257, 'entailment'], [258, 'entailment'], [259, 'entailment'], [260, 'entailment'], [261, 'entailment'], [262, 'entailment'], [263, 'entailment'], [264, 'entailment'], [265, 'entailment'], [266, 'entailment'], [267, 'entailment'], [268, 'entailment'], [269, 'entailment'], [270, 'entailment'], [271, 'entailment'], [272, 'entailment'], [273, 'entailment'], [274, 'entailment'], [275, 'entailment'], [276, 'entailment'], [277, 'entailment'], [278, 'entailment'], [279, 'entailment'], [280, 'entailment'], [281, 'entailment'], [282, 'entailment'], [283, 'entailment'], [284, 'entailment'], [285, 'entailment'], [286, 'entailment'], [287, 'entailment'], [288, 'entailment'], [289, 'entailment'], [290, 'entailment'], [291, 'entailment'], [292, 'entailment'], [293, 'entailment'], [294, 'entailment'], [295, 'entailment'], [296, 'entailment'], [297, 'entailment'], [298, 'entailment'], [299, 'entailment'], [300, 'entailment'], [301, 'entailment'], [302, 'entailment'], [303, 'entailment'], [304, 'entailment'], [305, 'entailment'], [306, 'entailment'], [307, 'entailment'], [308, 'entailment'], [309, 'entailment'], [310, 'entailment'], [311, 'entailment'], [312, 'entailment'], [313, 'entailment'], [314, 'entailment'], [315, 'entailment'], [316, 'entailment'], [317, 'entailment'], [318, 'entailment'], [319, 'entailment'], [320, 'entailment'], [321, 'entailment'], [322, 'entailment'], [323, 'entailment'], [324, 'entailment'], [325, 'entailment'], [326, 'entailment'], [327, 'entailment'], [328, 'entailment'], [329, 'entailment'], [330, 'entailment'], [331, 'entailment'], [332, 'entailment'], [333, 'entailment'], [334, 'entailment'], [335, 'entailment'], [336, 'entailment'], [337, 'entailment'], [338, 'entailment'], [339, 'entailment'], [340, 'entailment'], [341, 'entailment'], [342, 'entailment'], [343, 'entailment'], [344, 'entailment'], [345, 'entailment'], [346, 'entailment'], [347, 'entailment'], [348, 'entailment'], [349, 'entailment'], [350, 'entailment'], [351, 'entailment'], [352, 'entailment'], [353, 'entailment'], [354, 'entailment'], [355, 'entailment'], [356, 'entailment'], [357, 'entailment'], [358, 'entailment'], [359, 'entailment'], [360, 'entailment'], [361, 'entailment'], [362, 'entailment'], [363, 'entailment'], [364, 'entailment'], [365, 'entailment'], [366, 'entailment'], [367, 'entailment'], [368, 'entailment'], [369, 'entailment'], [370, 'entailment'], [371, 'entailment'], [372, 'entailment'], [373, 'entailment'], [374, 'entailment'], [375, 'entailment'], [376, 'entailment'], [377, 'entailment'], [378, 'entailment'], [379, 'entailment'], [380, 'entailment'], [381, 'entailment'], [382, 'entailment'], [383, 'entailment'], [384, 'entailment'], [385, 'entailment'], [386, 'entailment'], [387, 'entailment'], [388, 'entailment'], [389, 'entailment'], [390, 'entailment'], [391, 'entailment'], [392, 'entailment'], [393, 'entailment'], [394, 'entailment'], [395, 'entailment'], [396, 'entailment'], [397, 'entailment'], [398, 'entailment'], [399, 'entailment'], [400, 'entailment'], [401, 'entailment'], [402, 'entailment'], [403, 'entailment'], [404, 'entailment'], [405, 'entailment'], [406, 'entailment'], [407, 'entailment'], [408, 'entailment'], [409, 'entailment'], [410, 'entailment'], [411, 'entailment'], [412, 'entailment'], [413, 'entailment'], [414, 'entailment'], [415, 'entailment'], [416, 'entailment'], [417, 'entailment'], [418, 'entailment'], [419, 'entailment'], [420, 'entailment'], [421, 'entailment'], [422, 'entailment'], [423, 'entailment'], [424, 'entailment'], [425, 'entailment'], [426, 'entailment'], [427, 'entailment'], [428, 'entailment'], [429, 'entailment'], [430, 'entailment'], [431, 'entailment'], [432, 'entailment'], [433, 'entailment'], [434, 'entailment'], [435, 'entailment'], [436, 'entailment'], [437, 'entailment'], [438, 'entailment'], [439, 'entailment'], [440, 'entailment'], [441, 'entailment'], [442, 'entailment'], [443, 'entailment'], [444, 'entailment'], [445, 'entailment'], [446, 'entailment'], [447, 'entailment'], [448, 'entailment'], [449, 'entailment'], [450, 'entailment'], [451, 'entailment'], [452, 'entailment'], [453, 'entailment'], [454, 'entailment'], [455, 'entailment'], [456, 'entailment'], [457, 'entailment'], [458, 'entailment'], [459, 'entailment'], [460, 'entailment'], [461, 'entailment'], [462, 'entailment'], [463, 'entailment'], [464, 'entailment'], [465, 'entailment'], [466, 'entailment'], [467, 'entailment'], [468, 'entailment'], [469, 'entailment'], [470, 'entailment'], [471, 'entailment'], [472, 'entailment'], [473, 'entailment'], [474, 'entailment'], [475, 'entailment'], [476, 'entailment'], [477, 'entailment'], [478, 'entailment'], [479, 'entailment'], [480, 'entailment'], [481, 'entailment'], [482, 'entailment'], [483, 'entailment'], [484, 'entailment'], [485, 'entailment'], [486, 'entailment'], [487, 'entailment'], [488, 'entailment'], [489, 'entailment'], [490, 'entailment'], [491, 'entailment'], [492, 'entailment'], [493, 'entailment'], [494, 'entailment'], [495, 'entailment'], [496, 'entailment'], [497, 'entailment'], [498, 'entailment'], [499, 'entailment'], [500, 'entailment'], [501, 'entailment'], [502, 'entailment'], [503, 'entailment'], [504, 'entailment'], [505, 'entailment'], [506, 'entailment'], [507, 'entailment'], [508, 'entailment'], [509, 'entailment'], [510, 'entailment'], [511, 'entailment'], [512, 'entailment'], [513, 'entailment'], [514, 'entailment'], [515, 'entailment'], [516, 'entailment'], [517, 'entailment'], [518, 'entailment'], [519, 'entailment'], [520, 'entailment'], [521, 'entailment'], [522, 'entailment'], [523, 'entailment'], [524, 'entailment'], [525, 'entailment'], [526, 'entailment'], [527, 'entailment'], [528, 'entailment'], [529, 'entailment'], [530, 'entailment'], [531, 'entailment'], [532, 'entailment'], [533, 'entailment'], [534, 'entailment'], [535, 'entailment'], [536, 'entailment'], [537, 'entailment'], [538, 'entailment'], [539, 'entailment'], [540, 'entailment'], [541, 'entailment'], [542, 'entailment'], [543, 'entailment'], [544, 'entailment'], [545, 'entailment'], [546, 'entailment'], [547, 'entailment'], [548, 'entailment'], [549, 'entailment'], [550, 'entailment'], [551, 'entailment'], [552, 'entailment'], [553, 'entailment'], [554, 'entailment'], [555, 'entailment'], [556, 'entailment'], [557, 'entailment'], [558, 'entailment'], [559, 'entailment'], [560, 'entailment'], [561, 'entailment'], [562, 'entailment'], [563, 'entailment'], [564, 'entailment'], [565, 'entailment'], [566, 'entailment'], [567, 'entailment'], [568, 'entailment'], [569, 'entailment'], [570, 'entailment'], [571, 'entailment'], [572, 'entailment'], [573, 'entailment'], [574, 'entailment'], [575, 'entailment'], [576, 'entailment'], [577, 'entailment'], [578, 'entailment'], [579, 'entailment'], [580, 'entailment'], [581, 'entailment'], [582, 'entailment'], [583, 'entailment'], [584, 'entailment'], [585, 'entailment'], [586, 'entailment'], [587, 'entailment'], [588, 'entailment'], [589, 'entailment'], [590, 'entailment'], [591, 'entailment'], [592, 'entailment'], [593, 'entailment'], [594, 'entailment'], [595, 'entailment'], [596, 'entailment'], [597, 'entailment'], [598, 'entailment'], [599, 'entailment'], [600, 'entailment'], [601, 'entailment'], [602, 'entailment'], [603, 'entailment'], [604, 'entailment'], [605, 'entailment'], [606, 'entailment'], [607, 'entailment'], [608, 'entailment'], [609, 'entailment'], [610, 'entailment'], [611, 'entailment'], [612, 'entailment'], [613, 'entailment'], [614, 'entailment'], [615, 'entailment'], [616, 'entailment'], [617, 'entailment'], [618, 'entailment'], [619, 'entailment'], [620, 'entailment'], [621, 'entailment'], [622, 'entailment'], [623, 'entailment'], [624, 'entailment'], [625, 'entailment'], [626, 'entailment'], [627, 'entailment'], [628, 'entailment'], [629, 'entailment'], [630, 'entailment'], [631, 'entailment'], [632, 'entailment'], [633, 'entailment'], [634, 'entailment'], [635, 'entailment'], [636, 'entailment'], [637, 'entailment'], [638, 'entailment'], [639, 'entailment'], [640, 'entailment'], [641, 'entailment'], [642, 'entailment'], [643, 'entailment'], [644, 'entailment'], [645, 'entailment'], [646, 'entailment'], [647, 'entailment'], [648, 'entailment'], [649, 'entailment'], [650, 'entailment'], [651, 'entailment'], [652, 'entailment'], [653, 'entailment'], [654, 'entailment'], [655, 'entailment'], [656, 'entailment'], [657, 'entailment'], [658, 'entailment'], [659, 'entailment'], [660, 'entailment'], [661, 'entailment'], [662, 'entailment'], [663, 'entailment'], [664, 'entailment'], [665, 'entailment'], [666, 'entailment'], [667, 'entailment'], [668, 'entailment'], [669, 'entailment'], [670, 'entailment'], [671, 'entailment'], [672, 'entailment'], [673, 'entailment'], [674, 'entailment'], [675, 'entailment'], [676, 'entailment'], [677, 'entailment'], [678, 'entailment'], [679, 'entailment'], [680, 'entailment'], [681, 'entailment'], [682, 'entailment'], [683, 'entailment'], [684, 'entailment'], [685, 'entailment'], [686, 'entailment'], [687, 'entailment'], [688, 'entailment'], [689, 'entailment'], [690, 'entailment'], [691, 'entailment'], [692, 'entailment'], [693, 'entailment'], [694, 'entailment'], [695, 'entailment'], [696, 'entailment'], [697, 'entailment'], [698, 'entailment'], [699, 'entailment'], [700, 'entailment'], [701, 'entailment'], [702, 'entailment'], [703, 'entailment'], [704, 'entailment'], [705, 'entailment'], [706, 'entailment'], [707, 'entailment'], [708, 'entailment'], [709, 'entailment'], [710, 'entailment'], [711, 'entailment'], [712, 'entailment'], [713, 'entailment'], [714, 'entailment'], [715, 'entailment'], [716, 'entailment'], [717, 'entailment'], [718, 'entailment'], [719, 'entailment'], [720, 'entailment'], [721, 'entailment'], [722, 'entailment'], [723, 'entailment'], [724, 'entailment'], [725, 'entailment'], [726, 'entailment'], [727, 'entailment'], [728, 'entailment'], [729, 'entailment'], [730, 'entailment'], [731, 'entailment'], [732, 'entailment'], [733, 'entailment'], [734, 'entailment'], [735, 'entailment'], [736, 'entailment'], [737, 'entailment'], [738, 'entailment'], [739, 'entailment'], [740, 'entailment'], [741, 'entailment'], [742, 'entailment'], [743, 'entailment'], [744, 'entailment'], [745, 'entailment'], [746, 'entailment'], [747, 'entailment'], [748, 'entailment'], [749, 'entailment'], [750, 'entailment'], [751, 'entailment'], [752, 'entailment'], [753, 'entailment'], [754, 'entailment'], [755, 'entailment'], [756, 'entailment'], [757, 'entailment'], [758, 'entailment'], [759, 'entailment'], [760, 'entailment'], [761, 'entailment'], [762, 'entailment'], [763, 'entailment'], [764, 'entailment'], [765, 'entailment'], [766, 'entailment'], [767, 'entailment'], [768, 'entailment'], [769, 'entailment'], [770, 'entailment'], [771, 'entailment'], [772, 'entailment'], [773, 'entailment'], [774, 'entailment'], [775, 'entailment'], [776, 'entailment'], [777, 'entailment'], [778, 'entailment'], [779, 'entailment'], [780, 'entailment'], [781, 'entailment'], [782, 'entailment'], [783, 'entailment'], [784, 'entailment'], [785, 'entailment'], [786, 'entailment'], [787, 'entailment'], [788, 'entailment'], [789, 'entailment'], [790, 'entailment'], [791, 'entailment'], [792, 'entailment'], [793, 'entailment'], [794, 'entailment'], [795, 'entailment'], [796, 'entailment'], [797, 'entailment'], [798, 'entailment'], [799, 'entailment'], [800, 'entailment'], [801, 'entailment'], [802, 'entailment'], [803, 'entailment'], [804, 'entailment'], [805, 'entailment'], [806, 'entailment'], [807, 'entailment'], [808, 'entailment'], [809, 'entailment'], [810, 'entailment'], [811, 'entailment'], [812, 'entailment'], [813, 'entailment'], [814, 'entailment'], [815, 'entailment'], [816, 'entailment'], [817, 'entailment'], [818, 'entailment'], [819, 'entailment'], [820, 'entailment'], [821, 'entailment'], [822, 'entailment'], [823, 'entailment'], [824, 'entailment'], [825, 'entailment'], [826, 'entailment'], [827, 'entailment'], [828, 'entailment'], [829, 'entailment'], [830, 'entailment'], [831, 'entailment'], [832, 'entailment'], [833, 'entailment'], [834, 'entailment'], [835, 'entailment'], [836, 'entailment'], [837, 'entailment'], [838, 'entailment'], [839, 'entailment'], [840, 'entailment'], [841, 'entailment'], [842, 'entailment'], [843, 'entailment'], [844, 'entailment'], [845, 'entailment'], [846, 'entailment'], [847, 'entailment'], [848, 'entailment'], [849, 'entailment'], [850, 'entailment'], [851, 'entailment'], [852, 'entailment'], [853, 'entailment'], [854, 'entailment'], [855, 'entailment'], [856, 'entailment'], [857, 'entailment'], [858, 'entailment'], [859, 'entailment'], [860, 'entailment'], [861, 'entailment'], [862, 'entailment'], [863, 'entailment'], [864, 'entailment'], [865, 'entailment'], [866, 'entailment'], [867, 'entailment'], [868, 'entailment'], [869, 'entailment'], [870, 'entailment'], [871, 'entailment'], [872, 'entailment'], [873, 'entailment'], [874, 'entailment'], [875, 'entailment'], [876, 'entailment'], [877, 'entailment'], [878, 'entailment'], [879, 'entailment'], [880, 'entailment'], [881, 'entailment'], [882, 'entailment'], [883, 'entailment'], [884, 'entailment'], [885, 'entailment'], [886, 'entailment'], [887, 'entailment'], [888, 'entailment'], [889, 'entailment'], [890, 'entailment'], [891, 'entailment'], [892, 'entailment'], [893, 'entailment'], [894, 'entailment'], [895, 'entailment'], [896, 'entailment'], [897, 'entailment'], [898, 'entailment'], [899, 'entailment'], [900, 'entailment'], [901, 'entailment'], [902, 'entailment'], [903, 'entailment'], [904, 'entailment'], [905, 'entailment'], [906, 'entailment'], [907, 'entailment'], [908, 'entailment'], [909, 'entailment'], [910, 'entailment'], [911, 'entailment'], [912, 'entailment'], [913, 'entailment'], [914, 'entailment'], [915, 'entailment'], [916, 'entailment'], [917, 'entailment'], [918, 'entailment'], [919, 'entailment'], [920, 'entailment'], [921, 'entailment'], [922, 'entailment'], [923, 'entailment'], [924, 'entailment'], [925, 'entailment'], [926, 'entailment'], [927, 'entailment'], [928, 'entailment'], [929, 'entailment'], [930, 'entailment'], [931, 'entailment'], [932, 'entailment'], [933, 'entailment'], [934, 'entailment'], [935, 'entailment'], [936, 'entailment'], [937, 'entailment'], [938, 'entailment'], [939, 'entailment'], [940, 'entailment'], [941, 'entailment'], [942, 'entailment'], [943, 'entailment'], [944, 'entailment'], [945, 'entailment'], [946, 'entailment'], [947, 'entailment'], [948, 'entailment'], [949, 'entailment'], [950, 'entailment'], [951, 'entailment'], [952, 'entailment'], [953, 'entailment'], [954, 'entailment'], [955, 'entailment'], [956, 'entailment'], [957, 'entailment'], [958, 'entailment'], [959, 'entailment'], [960, 'entailment'], [961, 'entailment'], [962, 'entailment'], [963, 'entailment'], [964, 'entailment'], [965, 'entailment'], [966, 'entailment'], [967, 'entailment'], [968, 'entailment'], [969, 'entailment'], [970, 'entailment'], [971, 'entailment'], [972, 'entailment'], [973, 'entailment'], [974, 'entailment'], [975, 'entailment'], [976, 'entailment'], [977, 'entailment'], [978, 'entailment'], [979, 'entailment'], [980, 'entailment'], [981, 'entailment'], [982, 'entailment'], [983, 'entailment'], [984, 'entailment'], [985, 'entailment'], [986, 'entailment'], [987, 'entailment'], [988, 'entailment'], [989, 'entailment'], [990, 'entailment'], [991, 'entailment'], [992, 'entailment'], [993, 'entailment'], [994, 'entailment'], [995, 'entailment'], [996, 'entailment'], [997, 'entailment'], [998, 'entailment'], [999, 'entailment'], [1000, 'entailment'], [1001, 'entailment'], [1002, 'entailment'], [1003, 'entailment'], [1004, 'entailment'], [1005, 'entailment'], [1006, 'entailment'], [1007, 'entailment'], [1008, 'entailment'], [1009, 'entailment'], [1010, 'entailment'], [1011, 'entailment'], [1012, 'entailment'], [1013, 'entailment'], [1014, 'entailment'], [1015, 'entailment'], [1016, 'entailment'], [1017, 'entailment'], [1018, 'entailment'], [1019, 'entailment'], [1020, 'entailment'], [1021, 'entailment'], [1022, 'entailment'], [1023, 'entailment'], [1024, 'entailment'], [1025, 'entailment'], [1026, 'entailment'], [1027, 'entailment'], [1028, 'entailment'], [1029, 'entailment'], [1030, 'entailment'], [1031, 'entailment'], [1032, 'entailment'], [1033, 'entailment'], [1034, 'entailment'], [1035, 'entailment'], [1036, 'entailment'], [1037, 'entailment'], [1038, 'entailment'], [1039, 'entailment'], [1040, 'entailment'], [1041, 'entailment'], [1042, 'entailment'], [1043, 'entailment'], [1044, 'entailment'], [1045, 'entailment'], [1046, 'entailment'], [1047, 'entailment'], [1048, 'entailment'], [1049, 'entailment'], [1050, 'entailment'], [1051, 'entailment'], [1052, 'entailment'], [1053, 'entailment'], [1054, 'entailment'], [1055, 'entailment'], [1056, 'entailment'], [1057, 'entailment'], [1058, 'entailment'], [1059, 'entailment'], [1060, 'entailment'], [1061, 'entailment'], [1062, 'entailment'], [1063, 'entailment'], [1064, 'entailment'], [1065, 'entailment'], [1066, 'entailment'], [1067, 'entailment'], [1068, 'entailment'], [1069, 'entailment'], [1070, 'entailment'], [1071, 'entailment'], [1072, 'entailment'], [1073, 'entailment'], [1074, 'entailment'], [1075, 'entailment'], [1076, 'entailment'], [1077, 'entailment'], [1078, 'entailment'], [1079, 'entailment'], [1080, 'entailment'], [1081, 'entailment'], [1082, 'entailment'], [1083, 'entailment'], [1084, 'entailment'], [1085, 'entailment'], [1086, 'entailment'], [1087, 'entailment'], [1088, 'entailment'], [1089, 'entailment'], [1090, 'entailment'], [1091, 'entailment'], [1092, 'entailment'], [1093, 'entailment'], [1094, 'entailment'], [1095, 'entailment'], [1096, 'entailment'], [1097, 'entailment'], [1098, 'entailment'], [1099, 'entailment'], [1100, 'entailment'], [1101, 'entailment'], [1102, 'entailment'], [1103, 'entailment'], [1104, 'entailment'], [1105, 'entailment'], [1106, 'entailment'], [1107, 'entailment'], [1108, 'entailment'], [1109, 'entailment'], [1110, 'entailment'], [1111, 'entailment'], [1112, 'entailment'], [1113, 'entailment'], [1114, 'entailment'], [1115, 'entailment'], [1116, 'entailment'], [1117, 'entailment'], [1118, 'entailment'], [1119, 'entailment'], [1120, 'entailment'], [1121, 'entailment'], [1122, 'entailment'], [1123, 'entailment'], [1124, 'entailment'], [1125, 'entailment'], [1126, 'entailment'], [1127, 'entailment'], [1128, 'entailment'], [1129, 'entailment'], [1130, 'entailment'], [1131, 'entailment'], [1132, 'entailment'], [1133, 'entailment'], [1134, 'entailment'], [1135, 'entailment'], [1136, 'entailment'], [1137, 'entailment'], [1138, 'entailment'], [1139, 'entailment'], [1140, 'entailment'], [1141, 'entailment'], [1142, 'entailment'], [1143, 'entailment'], [1144, 'entailment'], [1145, 'entailment'], [1146, 'entailment'], [1147, 'entailment'], [1148, 'entailment'], [1149, 'entailment'], [1150, 'entailment'], [1151, 'entailment'], [1152, 'entailment'], [1153, 'entailment'], [1154, 'entailment'], [1155, 'entailment'], [1156, 'entailment'], [1157, 'entailment'], [1158, 'entailment'], [1159, 'entailment'], [1160, 'entailment'], [1161, 'entailment'], [1162, 'entailment'], [1163, 'entailment'], [1164, 'entailment'], [1165, 'entailment'], [1166, 'entailment'], [1167, 'entailment'], [1168, 'entailment'], [1169, 'entailment'], [1170, 'entailment'], [1171, 'entailment'], [1172, 'entailment'], [1173, 'entailment'], [1174, 'entailment'], [1175, 'entailment'], [1176, 'entailment'], [1177, 'entailment'], [1178, 'entailment'], [1179, 'entailment'], [1180, 'entailment'], [1181, 'entailment'], [1182, 'entailment'], [1183, 'entailment'], [1184, 'entailment'], [1185, 'entailment'], [1186, 'entailment'], [1187, 'entailment'], [1188, 'entailment'], [1189, 'entailment'], [1190, 'entailment'], [1191, 'entailment'], [1192, 'entailment'], [1193, 'entailment'], [1194, 'entailment'], [1195, 'entailment'], [1196, 'entailment'], [1197, 'entailment'], [1198, 'entailment'], [1199, 'entailment'], [1200, 'entailment'], [1201, 'entailment'], [1202, 'entailment'], [1203, 'entailment'], [1204, 'entailment'], [1205, 'entailment'], [1206, 'entailment'], [1207, 'entailment'], [1208, 'entailment'], [1209, 'entailment'], [1210, 'entailment'], [1211, 'entailment'], [1212, 'entailment'], [1213, 'entailment'], [1214, 'entailment'], [1215, 'entailment'], [1216, 'entailment'], [1217, 'entailment'], [1218, 'entailment'], [1219, 'entailment'], [1220, 'entailment'], [1221, 'entailment'], [1222, 'entailment'], [1223, 'entailment'], [1224, 'entailment'], [1225, 'entailment'], [1226, 'entailment'], [1227, 'entailment'], [1228, 'entailment'], [1229, 'entailment'], [1230, 'entailment'], [1231, 'entailment'], [1232, 'entailment'], [1233, 'entailment'], [1234, 'entailment'], [1235, 'entailment'], [1236, 'entailment'], [1237, 'entailment'], [1238, 'entailment'], [1239, 'entailment'], [1240, 'entailment'], [1241, 'entailment'], [1242, 'entailment'], [1243, 'entailment'], [1244, 'entailment'], [1245, 'entailment'], [1246, 'entailment'], [1247, 'entailment'], [1248, 'entailment'], [1249, 'entailment'], [1250, 'entailment'], [1251, 'entailment'], [1252, 'entailment'], [1253, 'entailment'], [1254, 'entailment'], [1255, 'entailment'], [1256, 'entailment'], [1257, 'entailment'], [1258, 'entailment'], [1259, 'entailment'], [1260, 'entailment'], [1261, 'entailment'], [1262, 'entailment'], [1263, 'entailment'], [1264, 'entailment'], [1265, 'entailment'], [1266, 'entailment'], [1267, 'entailment'], [1268, 'entailment'], [1269, 'entailment'], [1270, 'entailment'], [1271, 'entailment'], [1272, 'entailment'], [1273, 'entailment'], [1274, 'entailment'], [1275, 'entailment'], [1276, 'entailment'], [1277, 'entailment'], [1278, 'entailment'], [1279, 'entailment'], [1280, 'entailment'], [1281, 'entailment'], [1282, 'entailment'], [1283, 'entailment'], [1284, 'entailment'], [1285, 'entailment'], [1286, 'entailment'], [1287, 'entailment'], [1288, 'entailment'], [1289, 'entailment'], [1290, 'entailment'], [1291, 'entailment'], [1292, 'entailment'], [1293, 'entailment'], [1294, 'entailment'], [1295, 'entailment'], [1296, 'entailment'], [1297, 'entailment'], [1298, 'entailment'], [1299, 'entailment'], [1300, 'entailment'], [1301, 'entailment'], [1302, 'entailment'], [1303, 'entailment'], [1304, 'entailment'], [1305, 'entailment'], [1306, 'entailment'], [1307, 'entailment'], [1308, 'entailment'], [1309, 'entailment'], [1310, 'entailment'], [1311, 'entailment'], [1312, 'entailment'], [1313, 'entailment'], [1314, 'entailment'], [1315, 'entailment'], [1316, 'entailment'], [1317, 'entailment'], [1318, 'entailment'], [1319, 'entailment'], [1320, 'entailment'], [1321, 'entailment'], [1322, 'entailment'], [1323, 'entailment'], [1324, 'entailment'], [1325, 'entailment'], [1326, 'entailment'], [1327, 'entailment'], [1328, 'entailment'], [1329, 'entailment'], [1330, 'entailment'], [1331, 'entailment'], [1332, 'entailment'], [1333, 'entailment'], [1334, 'entailment'], [1335, 'entailment'], [1336, 'entailment'], [1337, 'entailment'], [1338, 'entailment'], [1339, 'entailment'], [1340, 'entailment'], [1341, 'entailment'], [1342, 'entailment'], [1343, 'entailment'], [1344, 'entailment'], [1345, 'entailment'], [1346, 'entailment'], [1347, 'entailment'], [1348, 'entailment'], [1349, 'entailment'], [1350, 'entailment'], [1351, 'entailment'], [1352, 'entailment'], [1353, 'entailment'], [1354, 'entailment'], [1355, 'entailment'], [1356, 'entailment'], [1357, 'entailment'], [1358, 'entailment'], [1359, 'entailment'], [1360, 'entailment'], [1361, 'entailment'], [1362, 'entailment'], [1363, 'entailment'], [1364, 'entailment'], [1365, 'entailment'], [1366, 'entailment'], [1367, 'entailment'], [1368, 'entailment'], [1369, 'entailment'], [1370, 'entailment'], [1371, 'entailment'], [1372, 'entailment'], [1373, 'entailment'], [1374, 'entailment'], [1375, 'entailment'], [1376, 'entailment'], [1377, 'entailment'], [1378, 'entailment'], [1379, 'entailment'], [1380, 'entailment'], [1381, 'entailment'], [1382, 'entailment'], [1383, 'entailment'], [1384, 'entailment'], [1385, 'entailment'], [1386, 'entailment'], [1387, 'entailment'], [1388, 'entailment'], [1389, 'entailment'], [1390, 'entailment'], [1391, 'entailment'], [1392, 'entailment'], [1393, 'entailment'], [1394, 'entailment'], [1395, 'entailment'], [1396, 'entailment'], [1397, 'entailment'], [1398, 'entailment'], [1399, 'entailment'], [1400, 'entailment'], [1401, 'entailment'], [1402, 'entailment'], [1403, 'entailment'], [1404, 'entailment'], [1405, 'entailment'], [1406, 'entailment'], [1407, 'entailment'], [1408, 'entailment'], [1409, 'entailment'], [1410, 'entailment'], [1411, 'entailment'], [1412, 'entailment'], [1413, 'entailment'], [1414, 'entailment'], [1415, 'entailment'], [1416, 'entailment'], [1417, 'entailment'], [1418, 'entailment'], [1419, 'entailment'], [1420, 'entailment'], [1421, 'entailment'], [1422, 'entailment'], [1423, 'entailment'], [1424, 'entailment'], [1425, 'entailment'], [1426, 'entailment'], [1427, 'entailment'], [1428, 'entailment'], [1429, 'entailment'], [1430, 'entailment'], [1431, 'entailment'], [1432, 'entailment'], [1433, 'entailment'], [1434, 'entailment'], [1435, 'entailment'], [1436, 'entailment'], [1437, 'entailment'], [1438, 'entailment'], [1439, 'entailment'], [1440, 'entailment'], [1441, 'entailment'], [1442, 'entailment'], [1443, 'entailment'], [1444, 'entailment'], [1445, 'entailment'], [1446, 'entailment'], [1447, 'entailment'], [1448, 'entailment'], [1449, 'entailment'], [1450, 'entailment'], [1451, 'entailment'], [1452, 'entailment'], [1453, 'entailment'], [1454, 'entailment'], [1455, 'entailment'], [1456, 'entailment'], [1457, 'entailment'], [1458, 'entailment'], [1459, 'entailment'], [1460, 'entailment'], [1461, 'entailment'], [1462, 'entailment'], [1463, 'entailment'], [1464, 'entailment'], [1465, 'entailment'], [1466, 'entailment'], [1467, 'entailment'], [1468, 'entailment'], [1469, 'entailment'], [1470, 'entailment'], [1471, 'entailment'], [1472, 'entailment'], [1473, 'entailment'], [1474, 'entailment'], [1475, 'entailment'], [1476, 'entailment'], [1477, 'entailment'], [1478, 'entailment'], [1479, 'entailment'], [1480, 'entailment'], [1481, 'entailment'], [1482, 'entailment'], [1483, 'entailment'], [1484, 'entailment'], [1485, 'entailment'], [1486, 'entailment'], [1487, 'entailment'], [1488, 'entailment'], [1489, 'entailment'], [1490, 'entailment'], [1491, 'entailment'], [1492, 'entailment'], [1493, 'entailment'], [1494, 'entailment'], [1495, 'entailment'], [1496, 'entailment'], [1497, 'entailment'], [1498, 'entailment'], [1499, 'entailment'], [1500, 'entailment'], [1501, 'entailment'], [1502, 'entailment'], [1503, 'entailment'], [1504, 'entailment'], [1505, 'entailment'], [1506, 'entailment'], [1507, 'entailment'], [1508, 'entailment'], [1509, 'entailment'], [1510, 'entailment'], [1511, 'entailment'], [1512, 'entailment'], [1513, 'entailment'], [1514, 'entailment'], [1515, 'entailment'], [1516, 'entailment'], [1517, 'entailment'], [1518, 'entailment'], [1519, 'entailment'], [1520, 'entailment'], [1521, 'entailment'], [1522, 'entailment'], [1523, 'entailment'], [1524, 'entailment'], [1525, 'entailment'], [1526, 'entailment'], [1527, 'entailment'], [1528, 'entailment'], [1529, 'entailment'], [1530, 'entailment'], [1531, 'entailment'], [1532, 'entailment'], [1533, 'entailment'], [1534, 'entailment'], [1535, 'entailment'], [1536, 'entailment'], [1537, 'entailment'], [1538, 'entailment'], [1539, 'entailment'], [1540, 'entailment'], [1541, 'entailment'], [1542, 'entailment'], [1543, 'entailment'], [1544, 'entailment'], [1545, 'entailment'], [1546, 'entailment'], [1547, 'entailment'], [1548, 'entailment'], [1549, 'entailment'], [1550, 'entailment'], [1551, 'entailment'], [1552, 'entailment'], [1553, 'entailment'], [1554, 'entailment'], [1555, 'entailment'], [1556, 'entailment'], [1557, 'entailment'], [1558, 'entailment'], [1559, 'entailment'], [1560, 'entailment'], [1561, 'entailment'], [1562, 'entailment'], [1563, 'entailment'], [1564, 'entailment'], [1565, 'entailment'], [1566, 'entailment'], [1567, 'entailment'], [1568, 'entailment'], [1569, 'entailment'], [1570, 'entailment'], [1571, 'entailment'], [1572, 'entailment'], [1573, 'entailment'], [1574, 'entailment'], [1575, 'entailment'], [1576, 'entailment'], [1577, 'entailment'], [1578, 'entailment'], [1579, 'entailment'], [1580, 'entailment'], [1581, 'entailment'], [1582, 'entailment'], [1583, 'entailment'], [1584, 'entailment'], [1585, 'entailment'], [1586, 'entailment'], [1587, 'entailment'], [1588, 'entailment'], [1589, 'entailment'], [1590, 'entailment'], [1591, 'entailment'], [1592, 'entailment'], [1593, 'entailment'], [1594, 'entailment'], [1595, 'entailment'], [1596, 'entailment'], [1597, 'entailment'], [1598, 'entailment'], [1599, 'entailment'], [1600, 'entailment'], [1601, 'entailment'], [1602, 'entailment'], [1603, 'entailment'], [1604, 'entailment'], [1605, 'entailment'], [1606, 'entailment'], [1607, 'entailment'], [1608, 'entailment'], [1609, 'entailment'], [1610, 'entailment'], [1611, 'entailment'], [1612, 'entailment'], [1613, 'entailment'], [1614, 'entailment'], [1615, 'entailment'], [1616, 'entailment'], [1617, 'entailment'], [1618, 'entailment'], [1619, 'entailment'], [1620, 'entailment'], [1621, 'entailment'], [1622, 'entailment'], [1623, 'entailment'], [1624, 'entailment'], [1625, 'entailment'], [1626, 'entailment'], [1627, 'entailment'], [1628, 'entailment'], [1629, 'entailment'], [1630, 'entailment'], [1631, 'entailment'], [1632, 'entailment'], [1633, 'entailment'], [1634, 'entailment'], [1635, 'entailment'], [1636, 'entailment'], [1637, 'entailment'], [1638, 'entailment'], [1639, 'entailment'], [1640, 'entailment'], [1641, 'entailment'], [1642, 'entailment'], [1643, 'entailment'], [1644, 'entailment'], [1645, 'entailment'], [1646, 'entailment'], [1647, 'entailment'], [1648, 'entailment'], [1649, 'entailment'], [1650, 'entailment'], [1651, 'entailment'], [1652, 'entailment'], [1653, 'entailment'], [1654, 'entailment'], [1655, 'entailment'], [1656, 'entailment'], [1657, 'entailment'], [1658, 'entailment'], [1659, 'entailment'], [1660, 'entailment'], [1661, 'entailment'], [1662, 'entailment'], [1663, 'entailment'], [1664, 'entailment'], [1665, 'entailment']]\n"
          ]
        }
      ],
      "source": [
        "def num_to_label(label):\n",
        "    label_dict = {0: \"entailment\", 1: \"contradiction\", 2: \"neutral\"}\n",
        "    str_label = []\n",
        "\n",
        "    for i, v in enumerate(label):\n",
        "        str_label.append([i,label_dict[v]])\n",
        "    \n",
        "    return str_label\n",
        "\n",
        "answer = num_to_label(pred_answer)\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg9PXCpWjDn2",
        "outputId": "98fcab84-2f26-44c8-daf1-28b28cafd514"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      index       label\n",
            "0         0  entailment\n",
            "1         1  entailment\n",
            "2         2  entailment\n",
            "3         3  entailment\n",
            "4         4  entailment\n",
            "...     ...         ...\n",
            "1661   1661  entailment\n",
            "1662   1662  entailment\n",
            "1663   1663  entailment\n",
            "1664   1664  entailment\n",
            "1665   1665  entailment\n",
            "\n",
            "[1666 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(answer, columns=['index', 'label'])\n",
        "\n",
        "df.to_csv('./result/submission.csv', index=False)\n",
        "\n",
        "print(df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('struggle')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "c014defca481e07b590e8e37c9be8c5cc93d6e595cb3271c6e722904d1c7641d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
